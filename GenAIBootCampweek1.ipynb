{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNw2Vx/EzLfWaqADgPXNxmM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnGreco192/Free_GenAI_Bootcamp_2025/blob/main/GenAIBootCampweek1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "882ba392",
        "outputId": "b5d34e7f-b908-41f5-e982-03b2c908e513"
      },
      "source": [
        "!git clone https://github.com/ExamProCo/free-genai-bootcamp-2025.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'free-genai-bootcamp-2025'...\n",
            "remote: Enumerating objects: 457, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 457 (delta 17), reused 10 (delta 10), pack-reused 430 (from 1)\u001b[K\n",
            "Receiving objects: 100% (457/457), 4.35 MiB | 21.84 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb125990",
        "outputId": "3b3c4cb0-6193-454a-bd87-c5897debd1ef"
      },
      "source": [
        "import os\n",
        "\n",
        "file_path = 'routes/study_sessions.py' # Corrected path to be relative to the current directory\n",
        "\n",
        "# Get the content of the cell above this one (assuming the user will run this cell directly after the one with the code)\n",
        "# WARNING: This method is fragile and assumes the user runs this cell immediately after the target code cell.\n",
        "# A more robust method would involve reading the cell content programmatically if possible, or having the user copy-paste.\n",
        "# For demonstration, we'll use a placeholder or assume the previous cell's content is available.\n",
        "# In a real scenario with the Colab API, we would read the cell content by ID.\n",
        "# Since we don't have direct access to the previous cell's *source code* in this interaction flow,\n",
        "# I will generate the full content to be written based on the code I intended to put in that modify_cells command.\n",
        "\n",
        "file_content = \"\"\"\n",
        "import os\n",
        "from flask import request, jsonify, g\n",
        "from flask_cors import cross_origin\n",
        "from datetime import datetime\n",
        "import math\n",
        "import json # Import json to potentially handle request data\n",
        "\n",
        "def load(app):\n",
        "  # todo /study_sessions POST\n",
        "  # Implementing the POST /study_sessions route\n",
        "  @app.route('/study_sessions', methods=['POST']) # Added the intended route\n",
        "  @cross_origin()\n",
        "  def create_study_session():\n",
        "    try:\n",
        "      # Get group_id and study_activity_id from request JSON\n",
        "      data = request.get_json()\n",
        "      group_id = data.get('group_id')\n",
        "      study_activity_id = data.get('study_activity_id')\n",
        "\n",
        "      if not group_id or not study_activity_id:\n",
        "        return jsonify({\"error\": \"group_id and study_activity_id are required\"}), 400\n",
        "\n",
        "      cursor = app.db.cursor()\n",
        "\n",
        "      # Check if group_id and study_activity_id exist (optional but good practice)\n",
        "      cursor.execute(\"SELECT id FROM groups WHERE id = ?\", (group_id,))\n",
        "      group = cursor.fetchone()\n",
        "      if not group:\n",
        "          return jsonify({\"error\": f\"Group with id {group_id} not found\"}), 404\n",
        "\n",
        "      cursor.execute(\"SELECT id FROM study_activities WHERE id = ?\", (study_activity_id,))\n",
        "      activity = cursor.fetchone()\n",
        "      if not activity:\n",
        "          return jsonify({\"error\": f\"Study activity with id {study_activity_id} not found\"}), 404\n",
        "\n",
        "      # Insert the new study session\n",
        "      cursor.execute('''\n",
        "        INSERT INTO study_sessions (group_id, study_activity_id, created_at)\n",
        "        VALUES (?, ?, ?)\n",
        "      ''', (group_id, study_activity_id, datetime.utcnow().isoformat()))\n",
        "      app.db.commit()\n",
        "\n",
        "      # Get the ID of the newly created session\n",
        "      session_id = cursor.lastrowid\n",
        "\n",
        "      # For a new session, we might want to fetch words for this group\n",
        "      # and potentially create initial word_review_items if needed for the activity type.\n",
        "      # This part depends on the specific logic of study activities,\n",
        "      # but we'll add a placeholder for fetching words.\n",
        "\n",
        "      cursor.execute('''\n",
        "          SELECT w.id, w.kanji, w.romaji, w.english\n",
        "          FROM words w\n",
        "          JOIN word_groups wg ON w.id = wg.word_id\n",
        "          WHERE wg.group_id = ?\n",
        "      ''', (group_id,))\n",
        "      words_for_session = cursor.fetchall()\n",
        "\n",
        "\n",
        "      return jsonify({\n",
        "          \"message\": \"Study session created successfully\",\n",
        "          \"session_id\": session_id,\n",
        "          \"group_id\": group_id,\n",
        "          \"study_activity_id\": study_activity_id,\n",
        "          \"words_in_session\": [dict(word) for word in words_for_session] # Return words associated with the group\n",
        "          }), 201\n",
        "\n",
        "    except Exception as e:\n",
        "      app.db.get().rollback() # Rollback changes if something goes wrong\n",
        "      return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "  @app.route('/api/study-sessions', methods=['GET'])\n",
        "  @cross_origin()\n",
        "  def get_study_sessions():\n",
        "    try:\n",
        "      cursor = app.db.cursor()\n",
        "\n",
        "      # Get pagination parameters\n",
        "      page = request.args.get('page', 1, type=int)\n",
        "      per_page = request.args.get('per_page', 10, type=int)\n",
        "      offset = (page - 1) * per_page\n",
        "\n",
        "      # Get total count\n",
        "      cursor.execute('''\n",
        "        SELECT COUNT(*) as count\n",
        "        FROM study_sessions ss\n",
        "        JOIN groups g ON g.id = ss.group_id\n",
        "        JOIN study_activities sa ON sa.id = ss.study_activity_id\n",
        "      ''')\n",
        "      total_count = cursor.fetchone()['count']\n",
        "\n",
        "      # Get paginated sessions\n",
        "      cursor.execute('''\n",
        "        SELECT\n",
        "          ss.id,\n",
        "          ss.group_id,\n",
        "          g.name as group_name,\n",
        "          sa.id as activity_id,\n",
        "          sa.name as activity_name,\n",
        "          ss.created_at,\n",
        "          COUNT(wri.id) as review_items_count\n",
        "        FROM study_sessions ss\n",
        "        JOIN groups g ON g.id = ss.group_id\n",
        "        JOIN study_activities sa ON sa.id = ss.study_activity_id\n",
        "        LEFT JOIN word_review_items wri ON wri.study_session_id = ss.id\n",
        "        GROUP BY ss.id\n",
        "        ORDER BY ss.created_at DESC\n",
        "        LIMIT ? OFFSET ?\n",
        "      ''', (per_page, offset))\n",
        "      sessions = cursor.fetchall()\n",
        "\n",
        "      return jsonify({\n",
        "        'items': [{\n",
        "          'id': session['id'],\n",
        "          'group_id': session['group_id'],\n",
        "          'group_name': session['group_name'],\n",
        "          'activity_id': session['activity_id'],\n",
        "          'activity_name': session['activity_name'],\n",
        "          'start_time': session['created_at'],\n",
        "          'end_time': session['created_at'],  # For now, just use the same time since we don't track end time\n",
        "          'review_items_count': session['review_items_count']\n",
        "        } for session in sessions],\n",
        "        'total': total_count,\n",
        "        'page': page,\n",
        "        'per_page': per_page,\n",
        "        'total_pages': math.ceil(total_count / per_page)\n",
        "      })\n",
        "    except Exception as e:\n",
        "      return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "  @app.route('/api/study-sessions/<id>', methods=['GET'])\n",
        "  @cross_origin()\n",
        "  def get_study_session(id):\n",
        "    try:\n",
        "      cursor = app.db.cursor()\n",
        "\n",
        "      # Get session details\n",
        "      cursor.execute('''\n",
        "        SELECT\n",
        "          ss.id,\n",
        "          ss.group_id,\n",
        "          g.name as group_name,\n",
        "          sa.id as activity_id,\n",
        "          sa.name as activity_name,\n",
        "          ss.created_at,\n",
        "          COUNT(wri.id) as review_items_count\n",
        "        FROM study_sessions ss\n",
        "        JOIN groups g ON g.id = ss.group_id\n",
        "        JOIN study_activities sa ON sa.id = ss.study_activity_id\n",
        "        LEFT JOIN word_review_items wri ON wri.study_session_id = ss.id\n",
        "        WHERE ss.id = ?\n",
        "        GROUP BY ss.id\n",
        "      ''', (id,))\n",
        "\n",
        "      session = cursor.fetchone()\n",
        "      if not session:\n",
        "        return jsonify({\"error\": \"Study session not found\"}), 404\n",
        "\n",
        "      # Get pagination parameters\n",
        "      page = request.args.get('page', 1, type=int)\n",
        "      per_page = request.args.get('per_page', 10, type=int)\n",
        "      offset = (page - 1) * per_page\n",
        "\n",
        "      # Get the words reviewed in this session with their review status\n",
        "      cursor.execute('''\n",
        "        SELECT\n",
        "          w.*,\n",
        "          COALESCE(SUM(CASE WHEN wri.correct = 1 THEN 1 ELSE 0 END), 0) as session_correct_count,\n",
        "          COALESCE(SUM(CASE WHEN wri.correct = 0 THEN 1 ELSE 0 END), 0) as session_wrong_count\n",
        "        FROM words w\n",
        "        JOIN word_review_items wri ON wri.word_id = w.id\n",
        "        WHERE wri.study_session_id = ?\n",
        "        GROUP BY w.id\n",
        "        ORDER BY w.kanji\n",
        "        LIMIT ? OFFSET ?\n",
        "      ''', (id, per_page, offset))\n",
        "\n",
        "      words = cursor.fetchall()\n",
        "\n",
        "      # Get total count of words\n",
        "      cursor.execute('''\n",
        "        SELECT COUNT(DISTINCT w.id) as count\n",
        "        FROM words w\n",
        "        JOIN word_review_items wri ON wri.word_id = w.id\n",
        "        WHERE wri.study_session_id = ?\n",
        "      ''', (id,))\n",
        "\n",
        "      total_count = cursor.fetchone()['count']\n",
        "\n",
        "      return jsonify({\n",
        "        'session': {\n",
        "          'id': session['id'],\n",
        "          'group_id': session['group_id'],\n",
        "          'group_name': session['group_name'],\n",
        "          'activity_id': session['activity_id'],\n",
        "          'activity_name': session['activity_name'],\n",
        "          'start_time': session['created_at'],\n",
        "          'end_time': session['created_at'],  # For now, just use the same time\n",
        "          'review_items_count': session['review_items_count']\n",
        "        },\n",
        "        'words': [{\n",
        "          'id': word['id'],\n",
        "          'kanji': word['kanji'],\n",
        "          'romaji': word['romaji'],\n",
        "          'english': word['english'],\n",
        "          'correct_count': word['session_correct_count'],\n",
        "          'wrong_count': word['session_wrong_count']\n",
        "        } for word in words],\n",
        "        'total': total_count,\n",
        "        'page': page,\n",
        "        'per_page': per_page,\n",
        "        'total_pages': math.ceil(total_count / per_page)\n",
        "      })\n",
        "    except Exception as e:\n",
        "      return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "  # todo POST /study_sessions/:id/review\n",
        "  # Implementing the POST /study_sessions/:id/review route\n",
        "  @app.route('/study_sessions/<int:id>/review', methods=['POST']) # Added the intended route\n",
        "  @cross_origin()\n",
        "  def log_review_attempt(id):\n",
        "      try:\n",
        "          # Get word_id and correct status from request JSON\n",
        "          data = request.get_json()\n",
        "          word_id = data.get('word_id')\n",
        "          correct = data.get('correct') # Expecting a boolean (True/False) or 1/0\n",
        "\n",
        "          if word_id is None or correct is None:\n",
        "              return jsonify({\"error\": \"word_id and correct status are required\"}), 400\n",
        "\n",
        "          # Convert correct to integer (1 for True, 0 for False)\n",
        "          correct_int = 1 if correct else 0\n",
        "\n",
        "          cursor = app.db.cursor()\n",
        "\n",
        "          # Check if the study session exists\n",
        "          cursor.execute(\"SELECT id FROM study_sessions WHERE id = ?\", (id,))\n",
        "          session = cursor.fetchone()\n",
        "          if not session:\n",
        "              return jsonify({\"error\": f\"Study session with id {id} not found\"}), 404\n",
        "\n",
        "          # Check if the word exists and is part of the session's group (optional validation)\n",
        "          # For simplicity, we'll just check if the word exists\n",
        "          cursor.execute(\"SELECT id FROM words WHERE id = ?\", (word_id,))\n",
        "          word = cursor.fetchone()\n",
        "          if not word:\n",
        "               return jsonify({\"error\": f\"Word with id {word_id} not found\"}), 404\n",
        "\n",
        "\n",
        "          # Insert the word review item\n",
        "          cursor.execute('''\n",
        "              INSERT INTO word_review_items (study_session_id, word_id, correct, created_at)\n",
        "              VALUES (?, ?, ?, ?)\n",
        "          ''', (id, word_id, correct_int, datetime.utcnow().isoformat()))\n",
        "          app.db.commit()\n",
        "\n",
        "          # Update the word_reviews table (or insert if not exists)\n",
        "          # This table aggregates review stats per word\n",
        "          cursor.execute('''\n",
        "              INSERT INTO word_reviews (word_id, correct_count, wrong_count)\n",
        "              VALUES (?, ?, ?)\n",
        "              ON CONFLICT(word_id) DO UPDATE SET\n",
        "                  correct_count = correct_count + excluded.correct_count,\n",
        "                  wrong_count = wrong_count + excluded.wrong_count;\n",
        "          ''', (word_id, correct_int, 1 - correct_int)) # Add 1 to correct_count if correct, else to wrong_count\n",
        "          app.db.commit()\n",
        "\n",
        "\n",
        "          return jsonify({\"message\": \"Review attempt logged successfully\"}), 201\n",
        "\n",
        "      except Exception as e:\n",
        "          app.db.get().rollback() # Rollback changes if something goes wrong\n",
        "          return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "  @app.route('/api/study-sessions/reset', methods=['POST'])\n",
        "  @cross_origin()\n",
        "  def reset_study_sessions():\n",
        "    try:\n",
        "      cursor = app.db.cursor()\n",
        "\n",
        "      # First delete all word review items since they have foreign key constraints\n",
        "      cursor.execute('DELETE FROM word_review_items')\n",
        "\n",
        "      # Then delete all study sessions\n",
        "      cursor.execute('DELETE FROM study_sessions')\n",
        "\n",
        "      # Also reset word_reviews table\n",
        "      cursor.execute('DELETE FROM word_reviews')\n",
        "\n",
        "\n",
        "      app.db.commit()\n",
        "\n",
        "      return jsonify({\"message\": \"Study history cleared successfully\"}), 200\n",
        "    except Exception as e:\n",
        "      app.db.get().rollback() # Rollback changes if something goes wrong\n",
        "      return jsonify({\"error\": str(e)}), 500\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(file_content)\n",
        "    print(f\"Successfully wrote content to '{file_path}'\")\n",
        "except Exception as e:\n",
        "    print(f\"Error writing to file '{file_path}': {e}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully wrote content to 'routes/study_sessions.py'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a505848",
        "outputId": "d09305cc-47f4-4084-eb5f-d89118449368"
      },
      "source": [
        "# Ensure you are in the backend directory\n",
        "%cd free-genai-bootcamp-2025/lang-portal/backend-flask\n",
        "\n",
        "# Run the database initialization task\n",
        "!invoke init-db"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'free-genai-bootcamp-2025/lang-portal/backend-flask'\n",
            "/content/free-genai-bootcamp-2025/lang-portal/backend-flask\n",
            "Successfully added 60 verbs to the 'Core Verbs' group.\n",
            "Successfully added 64 verbs to the 'Core Adjectives' group.\n",
            "Database initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6427f711",
        "outputId": "186af84a-4ee4-437a-8caa-d6c58ae412ff"
      },
      "source": [
        "# Install flask and ngrok\n",
        "!pip install Flask Flask-Cors pyngrok\n",
        "\n",
        "# Terminate any process using port 5000\n",
        "!fuser -k 5000/tcp\n",
        "\n",
        "# Navigate to the backend directory\n",
        "%cd free-genai-bootcamp-2025/lang-portal/backend-flask\n",
        "\n",
        "# Set the FLASK_APP environment variable\n",
        "%env FLASK_APP=app.py\n",
        "\n",
        "# Run the Flask application in a separate process and expose it with ngrok\n",
        "import subprocess\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import time\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "# Terminate open tunnels if any\n",
        "ngrok.kill()\n",
        "\n",
        "# Get the authtoken from Colab secrets\n",
        "NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
        "\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"NGROK_AUTH_TOKEN successfully loaded from Colab secrets.\")\n",
        "else:\n",
        "    print(\"NGROK_AUTH_TOKEN not found in Colab secrets.\")\n",
        "    print(\"Please add your authtoken to Colab secrets named 'NGROK_AUTH_TOKEN'.\")\n",
        "\n",
        "\n",
        "# Start Flask app using subprocess\n",
        "# Use a simple command, disabling debug and reloader for potentially more stability\n",
        "flask_process = subprocess.Popen(['flask', 'run', '--port', '5000', '--no-debugger', '--no-reload'])\n",
        "\n",
        "# Give the Flask app a moment to start\n",
        "time.sleep(5) # Increased sleep time\n",
        "\n",
        "# Open a tunnel to the Flask app\n",
        "try:\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"Flask app running at: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error starting ngrok tunnel: {e}\")\n",
        "    print(\"Attempting to terminate Flask process...\")\n",
        "    flask_process.terminate() # Attempt to stop the Flask process if ngrok fails\n",
        "    print(\"Flask process terminated.\")\n",
        "\n",
        "# Note: The flask_process is running in the background.\n",
        "# You might need to manually terminate it if you stop the cell execution\n",
        "# or if it doesn't shut down cleanly when the notebook session ends.\n",
        "# You can try !fuser -k 5000/tcp to kill it if needed."
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: Flask-Cors in /usr/local/lib/python3.11/dist-packages (6.0.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.8)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask) (1.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask) (3.0.2)\n",
            "5000/tcp:            60369\n",
            "[Errno 2] No such file or directory: 'free-genai-bootcamp-2025/lang-portal/backend-flask'\n",
            "/content/free-genai-bootcamp-2025/lang-portal/backend-flask\n",
            "env: FLASK_APP=app.py\n",
            "NGROK_AUTH_TOKEN successfully loaded from Colab secrets.\n",
            "Flask app running at: NgrokTunnel: \"https://152e-35-197-80-52.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38d825fc",
        "outputId": "d051a935-2f81-42a1-871c-cfa5e783f11a"
      },
      "source": [
        "import os\n",
        "\n",
        "backend_dir = '.' # Refer to the current directory\n",
        "\n",
        "print(f\"Contents of '{backend_dir}':\\n\")\n",
        "# List files and directories in the backend directory to find setup scripts\n",
        "for item in os.listdir(backend_dir):\n",
        "    print(item)\n",
        "\n",
        "print(\"\\nContents of 'sql/':\\n\")\n",
        "# List contents of the sql directory\n",
        "sql_dir = os.path.join(backend_dir, 'sql')\n",
        "if os.path.exists(sql_dir):\n",
        "    for item in os.listdir(sql_dir):\n",
        "        print(item)\n",
        "else:\n",
        "    print(f\"Directory '{sql_dir}' not found.\")\n",
        "\n",
        "print(\"\\nContents of 'seed/':\\n\")\n",
        "# List contents of the seed directory\n",
        "seed_dir = os.path.join(backend_dir, 'seed')\n",
        "if os.path.exists(seed_dir):\n",
        "    for item in os.listdir(seed_dir):\n",
        "        print(item)\n",
        "else:\n",
        "    print(f\"Directory '{seed_dir}' not found.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of '.':\n",
            "\n",
            "tasks.py\n",
            "seed\n",
            "app.py\n",
            "words.db\n",
            "migrate.py\n",
            "lib\n",
            "__pycache__\n",
            ".gitignore\n",
            "routes\n",
            "Readme.md\n",
            "requirements.txt\n",
            "sql\n",
            "\n",
            "Contents of 'sql/':\n",
            "\n",
            "setup\n",
            "\n",
            "Contents of 'seed/':\n",
            "\n",
            "study_activities.json\n",
            "data_adjectives.json\n",
            "data_verbs.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bb8a8cc",
        "outputId": "6404902a-3013-4640-c923-4353d6cb7231"
      },
      "source": [
        "import os\n",
        "\n",
        "tasks_file_path = 'tasks.py' # Corrected path\n",
        "migrate_file_path = 'migrate.py' # Corrected path\n",
        "sql_setup_dir_path = 'sql/setup' # Corrected to directory path\n",
        "\n",
        "\n",
        "print(f\"Contents of '{tasks_file_path}':\\n\")\n",
        "try:\n",
        "    with open(tasks_file_path, 'r') as f:\n",
        "        print(f.read())\n",
        "except FileNotFoundError:\n",
        "    print(f\"'{tasks_file_path}' not found.\")\n",
        "\n",
        "print(f\"\\nContents of '{migrate_file_path}':\\n\")\n",
        "try:\n",
        "    with open(migrate_file_path, 'r') as f:\n",
        "        print(f.read())\n",
        "except FileNotFoundError:\n",
        "    print(f\"'{migrate_file_path}' not found.\")\n",
        "\n",
        "print(f\"\\nContents of directory '{sql_setup_dir_path}':\\n\")\n",
        "try:\n",
        "    if os.path.isdir(sql_setup_dir_path):\n",
        "        for item in os.listdir(sql_setup_dir_path):\n",
        "            print(item)\n",
        "    else:\n",
        "        print(f\"'{sql_setup_dir_path}' is not a directory or does not exist.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Directory '{sql_setup_dir_path}' not found.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of 'tasks.py':\n",
            "\n",
            "from invoke import task\n",
            "from lib.db import db\n",
            "\n",
            "@task\n",
            "def init_db(c):\n",
            "  from flask import Flask\n",
            "  app = Flask(__name__)\n",
            "  db.init(app)\n",
            "  print(\"Database initialized successfully.\")\n",
            "\n",
            "Contents of 'migrate.py':\n",
            "\n",
            "import sqlite3\n",
            "import os\n",
            "\n",
            "def run_migrations():\n",
            "    # Connect to the database\n",
            "    db_path = os.path.join(os.path.dirname(__file__), 'word_bank.db')\n",
            "    conn = sqlite3.connect(db_path)\n",
            "    conn.row_factory = sqlite3.Row\n",
            "    \n",
            "    try:\n",
            "        # Get list of migration files\n",
            "        migrations_dir = os.path.join(os.path.dirname(__file__), 'sql', 'migrations')\n",
            "        migration_files = sorted([f for f in os.listdir(migrations_dir) if f.endswith('.sql')])\n",
            "        \n",
            "        # Run each migration\n",
            "        for migration_file in migration_files:\n",
            "            print(f\"Running migration: {migration_file}\")\n",
            "            with open(os.path.join(migrations_dir, migration_file)) as f:\n",
            "                migration_sql = f.read()\n",
            "                conn.executescript(migration_sql)\n",
            "                conn.commit()\n",
            "        \n",
            "        print(\"Migrations completed successfully\")\n",
            "    except Exception as e:\n",
            "        print(f\"Error running migrations: {str(e)}\")\n",
            "        conn.rollback()\n",
            "    finally:\n",
            "        conn.close()\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    run_migrations()\n",
            "\n",
            "\n",
            "Contents of directory 'sql/setup':\n",
            "\n",
            "create_table_groups.sql\n",
            "create_table_study_activities.sql\n",
            "create_table_word_reviews.sql\n",
            "create_table_study_sessions.sql\n",
            "create_table_words.sql\n",
            "create_word_reviews.sql\n",
            "create_table_word_groups.sql\n",
            "insert_study_activities.sql\n",
            "create_table_word_review_items.sql\n"
          ]
        }
      ]
    }
  ]
}